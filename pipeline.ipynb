{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import os\nos.chdir('readydemo')",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# ML Ops with Azure ML and Azure DevOps\n\n1. Create a training pipeline with Azure ML. \n2. Publish this pipeline so it can be used to control and automate the training process - including retraining later on.\n3. Use Azure DevOps to automate the release of your model once it is ready for E2E deployment.\n\nProblems to solve (DS):\n1. tracking my work\n2. iterating quickly as I experiment (and collaborate across my team)\n3. comparing and evaluating via leaderboards\n\nProblems to solve (DevOps):\n1. model reproducibility\n2. model valdidatio\n3. model versioning\n4. model deployment\n\n"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install gitpython",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Collecting gitpython\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/e5/fafe827507644c32d6dc553a1c435cdf882e0c28918a5bab29f7fbebfb70/GitPython-2.1.11-py2.py3-none-any.whl (448kB)\n\u001b[K    100% |████████████████████████████████| 450kB 28.0MB/s ta 0:00:01\n\u001b[?25hCollecting gitdb2>=2.0.0 (from gitpython)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/30/a407568aa8d8f25db817cf50121a958722f3fc5f87e3a6fba1f40c0633e3/gitdb2-2.0.5-py2.py3-none-any.whl (62kB)\n\u001b[K    100% |████████████████████████████████| 71kB 31.6MB/s ta 0:00:01\n\u001b[?25hCollecting smmap2>=2.0.0 (from gitdb2>=2.0.0->gitpython)\n  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\nInstalling collected packages: smmap2, gitdb2, gitpython\nSuccessfully installed gitdb2-2.0.5 gitpython-2.1.11 smmap2-2.0.5\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from azureml.core import Workspace, Datastore\nfrom azureml.core.compute import AmlCompute, DataFactoryCompute\nfrom azureml.core.runconfig import CondaDependencies, RunConfiguration\nfrom azureml.data.datapath import DataPath, DataPathComputeBinding\nfrom azureml.data.data_reference import DataReference\nfrom azureml.pipeline.core import Pipeline, PipelineData\nfrom azureml.pipeline.core.graph import PipelineParameter\nfrom azureml.pipeline.steps import PythonScriptStep\nfrom azureml.pipeline.steps import DataTransferStep\n\nimport git",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ws = Workspace.from_config()\nprint(ws.name, ws.resource_group, ws.location, ws.subscription_id, sep = '\\n')",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Found the config file in: /data/home/demo/notebooks/readydemo/config.json\ncontosomanufacturing\nscottgu-all-hands\neastus2\n2a779d6f-0806-4359-a6e8-f1fd57bb5dd7\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Declare resources you want to use:\n- Computes\n- Datastores (and data sets)\n- Configuration for training (Container Images / Conda Dependencies you want to use)"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "aml_compute_target = \"cpu\"\ndata_factory_name = \"adf\"\ndefault_dataset = \"soda_cans_training_data\"\nproject_folder = \"./mobilenetscripts\"\n\nds = ws.get_default_datastore()\nsource_ds = Datastore.get(ws, 'amlvdaik14969151586')\n\n# Declare packages dependencies required in the pipeline (these can also be expressed as a YML file)\ncd = CondaDependencies.create(pip_packages=[\"azureml-defaults\", 'tensorflow==1.8.0'])\namlcompute_run_config = RunConfiguration(conda_dependencies=cd)\n\n# Define our computes\ndata_factory_compute = DataFactoryCompute(ws, data_factory_name)\naml_compute = AmlCompute(ws, aml_compute_target)",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Define datasets you want to use"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "\n# We explicitly declare the data we're using in this training pipeline\nsource_images = DataReference(datastore=source_ds,\n                              data_reference_name=\"original_images\",\n                              path_on_datastore=default_dataset)\ndest_images = DataReference(datastore=ds,\n                            data_reference_name=\"transferred_images\",\n                            path_on_datastore='training_images')\nmlops = DataReference(datastore=ds,\n                      data_reference_name=\"mlops_connector\",\n                      path_on_datastore='mlops')\ntraining_dataset = DataPath(datastore=source_ds, path_on_datastore=default_dataset)",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Define pipeline parameters"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Parameters make it easy for us to re-run this training pipeline, including for retraining.\nmodel_variant = PipelineParameter(name=\"model_variant\", default_value='sodacans')\ntraining_dataset_param = (PipelineParameter(name=\"training_dataset\",\n                                            default_value=training_dataset),\n                          DataPathComputeBinding())\n\n\n# We pass the trained model from the transfer learning step to the model registration step\nmodel = PipelineData(name=\"model\", datastore=ds, output_path_on_compute=\"model\")\nmodel_id = PipelineData(name=\"modelId\", datastore=ds)\n",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Define pipeline steps\n\nPipeline steps are defined for:\n1. transferring and copying data\n2. training model (via transfer learning)\n3. Evaluating and registering the model to kick off the CI/CD process."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Copying data into a datastore we manage ensures we can reproduce the model later on.\ndatatransfer = DataTransferStep(\n    name=\"Copy training data for improved performance and model reproducibility\",\n    source_data_reference=source_images,\n    destination_data_reference=dest_images,\n    compute_target=data_factory_compute)\n\n\n# You'll note this is similar to the code from the notebook.\n# We've done some cleanup to reflect the proper parameterization of the steps.\n\n\n\ntrain = PythonScriptStep(name=\"Train new model via transfer learning\",\n                         script_name=\"train.py\",\n                         compute_target=aml_compute,\n                         runconfig=amlcompute_run_config,\n                         inputs=[training_dataset_param, dest_images],\n                         outputs=[model],\n                         source_directory=project_folder,\n                         arguments=['--image_dir', training_dataset_param,\n                                    '--architecture', 'mobilenet_1.0_224',\n                                    '--output_dir', model,\n                                    '--output_graph', 'retrained_graph.pb',\n                                    '--output_labels', 'output_labels.txt',\n                                    '--model_file_name', 'imagenet_2_frozen.pb'\n                                   ])\n\n\n\nregister = PythonScriptStep(name=\"Register model for deployment\",\n                            script_name=\"register.py\",\n                            compute_target=aml_compute,\n                            inputs=[model, mlops],\n                            arguments=['--dataset_name', model_variant,\n                                       '--model_assets_path', model\n                                      ],\n                            outputs=[model_id],\n                            source_directory=project_folder)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Create Pipeline"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "steps = [datatransfer, train, register]\npipeline = Pipeline(workspace=ws, steps=steps)\npipeline.validate()",
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Step Train new model via transfer learning is ready to be created [9275a21e]\nStep Register model for deployment is ready to be created [146610f4]\nData reference amlvdaik14969151586_e538dadb_f05f16b4 is ready to be created [7104c593], (Consumers of this data will generate new runs.)\n"
        },
        {
          "data": {
            "text/plain": "[]"
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Version your Code via Git Integration\n\nGit integration is one of our key upcoming mlops investment areas.\n\nWe are planning to support first-class tracking of code (for pipeline scripts, pipeline management, inference code management).\n\nTagging our training pipeline with repo/commit/branch information helps us flesh out the E2E audit trail for code (we can easily diff scripts between pipelines)."
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "repo = git.Repo(search_parent_directories=True)\ntags = {\n    'git.repo': repo.remotes.origin.url,\n    'git.commit': repo.head.object.hexsha,\n    'git.branch': repo.active_branch.name\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Publish Training Pipeline"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "\nmlpipeline = pipeline.publish(name=\"Ready ML Training Pipeline\",\n                              description=\"Retrain a mobilenet.imagenet model.\")\n\nprint(\"Pipeline Published ID:\"+mlpipeline.id)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Submit a Training Job to Classify Soda Cans"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "mlpipeline.submit(ws, \"sodacanclassifier\",\n                  pipeline_parameters={\"training_dataset\":DataPath(datastore=source_ds,\n                                                                   path_on_datastore=\"soda_cans_training_data\"),\n                                       \"model_variant\":\"sodacans\"}).set_tags(tags)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Your training pipeline experiment has been submitted successfully.\n\n[Click here to view your training experiment](https://ms.portal.azure.com/#@microsoft.onmicrosoft.com/resource/subscriptions/92c76a2f-0e1c-4216-b65e-abf7a3f34c1e/resourceGroups/DevOps_AzureML_Demo/providers/Microsoft.MachineLearningServices/workspaces/AzureML_Demo_ws/overview)"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# View CI/CD Pipeline for Your Model"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Azure DevOps, along with the Azure ML CLI, is used to automate the E2E release of your model.\n\nYou can view the release of your model [here](https://dev.azure.com/aidemos/DevOpsAIDemo/_releaseProgress?_a=release-pipeline-progress&releaseId=22)"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "display_name": "Python 3.6 - AzureML",
      "language": "python"
    },
    "language_info": {
      "version": "3.6.7",
      "nbconvert_exporter": "python",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      },
      "file_extension": ".py",
      "name": "python",
      "mimetype": "text/x-python",
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}